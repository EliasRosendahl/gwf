#!/Users/mailund/anaconda/bin/python

import os
import sys
import argparse

parser = argparse.ArgumentParser(description='Submit a workflow to the grid.')

parser.add_argument('-f', '--file', 
                    default='workflow.py', dest='workflow_file',
                    help='Workflow file if not the default (workflow.py).')
parser.add_argument('-d', '--dry-run', default=False, action='store_true',
                    help='The submit script will be printed but not executed.')
parser.add_argument('-s', '--status', default=False, action='store_true',
                    help='Print status of targets.')
parser.add_argument('-c', '--clean', default=False, action='store_true',
                    help='Delete output files generated by a target.')
parser.add_argument('-l', '--local', default=False, action='store_true',
                    help='Run the scripts locally. Mostly useful for debugging'
                    ' your workflows.')

parser.add_argument('targets', nargs='*',
                    help='The targets to process.')

args = parser.parse_args()
execfile(args.workflow_file)
from gwf_workflow.workflow import build_workflow, schedule
workflow = build_workflow()

if args.clean:
    if len(args.targets) == 0:
        print 'No targets specified to clean.'
        print 'To avoid horrible mistakes gwf will not clean default targets.'
        sys.exit(1)

    if args.dry_run:
        for target in args.targets:
            print 'Cleaning', target, 'will delete the following files:'
            print workflow.targets[target].get_existing_outfiles()
            print
    else:
        for target in args.targets:
            workflow.targets[target].clean_target()
        
    sys.exit(0)

if len(args.targets) > 0:
    all_targets = args.targets
else:
    # take all terminal nodes as default targets
    all_targets = [n.target.name for n in workflow.targets.values() if len(n.dependents) == 0]


if args.status:
    COLORS = {
        'red':    '\033[91m',
        'blue':   '\033[94m',
        'green':  '\033[32m',
        'black':  '\033[30m',
        'yellow': '\033[33m',
        'bold':   '\033[1m',
    }

    CLEAR = '\033[0m'

    all_scheduled = set()
    for target in all_targets:
        _, scheduled = schedule(workflow.targets, target)
        all_scheduled = scheduled.union(all_scheduled)

    in_queue = []
    scheduled = []
    up_to_data = []
    not_scheduled = []

    for node in workflow.targets.values():
        if node.job_in_queue:
            in_queue.append(node)
        elif node.target.name in all_scheduled:
            scheduled.append(node)
        else:
            if node.should_run:
                not_scheduled.append(node)
            else:
                up_to_data.append(node)

    for node in up_to_data:
        status = 'is up to date'
        print '{target} {status}'.format(
            target=(COLORS['bold']+node.target.name[:35]+CLEAR+'...'*50)[:50].ljust(50),
            status=COLORS['green']+status+CLEAR)

        # FIXME: This is a hack to avoid qstat'ing jobs that are no longer in queue. It isn't a pretty way to
        # handle this, but it will work until we get the new back-end.
        print type(node.target), dir(node.target)
        print type(node), dir(node)

    for node in not_scheduled:
        status = 'not scheduled for target(s)'
        print '{target} {status}'.format(
            target=(COLORS['bold']+node.target.name[:35]+CLEAR+'...'*50)[:50].ljust(50),
            status=COLORS['yellow']+status+CLEAR)

    for node in in_queue:
        status = 'in queue (%s: %s)' % (node.job_queue_status, node.jobID)
        print '{target} {status}'.format(
            target=(COLORS['bold']+node.target.name[:35]+CLEAR+'...'*50)[:50].ljust(50),
            status=COLORS['blue']+status+CLEAR)
    for node in scheduled:
        status = 'should be scheduled to run'
        print '{target} {status}'.format(
            target=(COLORS['bold']+node.target.name[:35]+CLEAR+'...'*50)[:50].ljust(50),
            status=COLORS['red']+status+CLEAR)

    sys.exit(0)


# Executing work flow!
if args.local:
    for target in all_targets:
        script = workflow.get_local_execution_script(target)
        if args.dry_run:
            print 'When run, the following script will be executed:'
            print
            print script
            print
        else:
            print 'Running script'
            print script
            os.system(script)
            print 'Done'

else:
    for target in all_targets:
        script = workflow.get_submission_script(target)
        if args.dry_run:
            print 'When run, the following script will be executed:'
            print
            print script
            print
        else:
            print 'Submitting jobs to queue...'
            os.system(script)
            print 'Done'
